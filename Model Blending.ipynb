{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Model Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_blending(model_list,model_weight):\n",
    "    \n",
    "    result = model_list[0]*model_weight[0]\n",
    "    N = len(model_list)\n",
    "    \n",
    "    for i in range(1,N):\n",
    "        result += model_list[i]*model_weight[i]\n",
    "    \n",
    "    result = result/np.sum(model_weight)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_submission(submission_list):\n",
    "    data_path = './zillow data/draft_submission'\n",
    "    model_list = []\n",
    "    for i in submission_list:\n",
    "        model = pd.read_csv(data_path +('%d.csv'%i),index_col=0)\n",
    "        model_list.append(model.copy())\n",
    "    \n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/venv/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "model_list = read_submission([5,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = np.ones(len(model_list))\n",
    "result = model_blending(model_list, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"./zillow data/combine_submission1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blending Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)  # seed to shuffle the train set\n",
    "n_folds = 10\n",
    "verbose = True\n",
    "shuffle = False\n",
    "\n",
    "if shuffle:\n",
    "    idx = np.random.permutation(y.size)\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "    \n",
    "skf = list(KFold(y, n_folds))\n",
    "\n",
    "models = []\n",
    "\n",
    "print \"Creating train and test sets for blending.\"\n",
    "dataset_blend_train = np.zeros((X.shape[0], len(models)))\n",
    "dataset_blend_test = np.zeros((X_submission.shape[0], len(models)))\n",
    "\n",
    "for j, model in enumerate(models):\n",
    "    print(j, model)\n",
    "    dataset_blend_test_j = np.zeros((X_submission.shape[0], len(skf)))\n",
    "        for i, (train, test) in enumerate(skf):\n",
    "            print(\"Fold\", i)\n",
    "            X_train = X[train]\n",
    "            y_train = y[train]\n",
    "            X_test = X[test]\n",
    "            y_test = y[test]\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            dataset_blend_train[test, j] = y_pred\n",
    "            dataset_blend_test_j[:, i] = model.predict(X_submission)\n",
    "        dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)\n",
    "    \n",
    "\n",
    "print(\"Blending.\")\n",
    "model = LogisticRegression()\n",
    "model.fit(dataset_blend_train, y)\n",
    "y_submission = model.predict(dataset_blend_test)\n",
    "\n",
    "print(\"Saving Results.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from vecstack import stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ExtraTreesRegressor(random_state=0, n_jobs=-1, \n",
    "                        n_estimators=100, max_depth=3),\n",
    "        \n",
    "    RandomForestRegressor(random_state=0, n_jobs=-1, \n",
    "                          n_estimators=100, max_depth=3),\n",
    "        \n",
    "    XGBRegressor(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
    "                 n_estimators=100, max_depth=3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_train, S_test = stacking(models,                     # list of models\n",
    "                           X_train, y_train, X_test,   # data\n",
    "                           regression=True,            # regression task (if you need \n",
    "                                                       #     classification - set to False)\n",
    "                           mode='oof_pred_bag',        # mode: oof for train set, predict test \n",
    "                                                       #     set in each fold and find mean\n",
    "                           save_dir=None,              # do not save result and log (to save \n",
    "                                                       #     in current dir - set to '.')\n",
    "                           metric=mean_absolute_error, # metric: callable\n",
    "                           n_folds=4,                  # number of folds\n",
    "                           shuffle=True,               # shuffle the data\n",
    "                           random_state=0,             # ensure reproducibility\n",
    "                           verbose=2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize 2nd level model\n",
    "model = XGBRegressor(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
    "                     n_estimators=100, max_depth=3)\n",
    "    \n",
    "# Fit 2nd level model\n",
    "model = model.fit(S_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(S_test)\n",
    "\n",
    "# Final prediction score\n",
    "print('Final prediction score: [%.8f]' % mean_absolute_error(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
