{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath_2016 = \"./zillow-data/merged_new2016.csv\"\n",
    "datapath_2017 = \"./zillow-data/merged_new2017.csv\"\n",
    "\n",
    "test_datapath_2016 = \"./zillow-data/properties_2016_new v2.csv\"\n",
    "test_datapath_2017 = \"./zillow-data/properties_2017_new.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify 'transactiondate' of df to keep only the month\n",
    "def parse_transactiondate(df):\n",
    "    # modify transactiondate col to keep only the month\n",
    "    new_transactiondate = []\n",
    "    for data in df['transactiondate']:\n",
    "        temp = data.split(\"-\")\n",
    "        new_transactiondate.append(int(temp[1])) # keep only month\n",
    "\n",
    "    new_transactiondate = np.array(new_transactiondate)\n",
    "    new_transactiondate = new_transactiondate.reshape(new_transactiondate.shape[0], 1)\n",
    "\n",
    "    df['transactiondate'] = new_transactiondate\n",
    "\n",
    "# return label index, feature index list\n",
    "# assumes that df label_is_first\n",
    "def split_on_label(df):\n",
    "    return df.columns[0], df.columns[1:]\n",
    "\n",
    "def gen_testdata(df, new_transactiondate):\n",
    "    df_copy = df.copy()\n",
    "    # df_copy['transactiondate'] = new_transactiondate\n",
    "    df_copy.insert(0, 'transactiondate', new_transactiondate)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016] num of features: 31\n",
      "[2016] num of instances: 90275\n",
      "[2017] num of features: 31\n",
      "[2017] num of instances: 77613\n"
     ]
    }
   ],
   "source": [
    "train_data2016 = pd.read_csv(datapath_2016, index_col=0)\n",
    "train_data2017 = pd.read_csv(datapath_2017, index_col=0)\n",
    "\n",
    "# --- TEMP Fixes for train_data2016 (not well formatted) ---\n",
    "# fix Unamed: 0 at col index 3\n",
    "fix_col = train_data2016.columns.str.contains('unnamed',case = False)\n",
    "train_data2016 = train_data2016.drop(train_data2016.columns[fix_col], axis=1)\n",
    "# --- END ---\n",
    "\n",
    "parcelid16 = train_data2016['parcelid']\n",
    "parcelid17 = train_data2017['parcelid']\n",
    "\n",
    "# drop parcelid (index of properties features)\n",
    "train_data2016 = train_data2016.drop('parcelid', axis=1)\n",
    "train_data2017 = train_data2017.drop('parcelid', axis=1)\n",
    "\n",
    "label16, feature16 = split_on_label(train_data2016)\n",
    "label17, feature17 = split_on_label(train_data2017)\n",
    "\n",
    "print(\"[2016] num of features:\", len(feature16))\n",
    "print(\"[2016] num of instances:\", train_data2016.shape[0])\n",
    "\n",
    "print(\"[2017] num of features:\", len(feature17))\n",
    "print(\"[2017] num of instances:\", train_data2017.shape[0])\n",
    "\n",
    "# modify 'transactiondate' to keep only the month\n",
    "parse_transactiondate(train_data2016)\n",
    "parse_transactiondate(train_data2017)\n",
    "\n",
    "# training data and label for model 2016\n",
    "X_train16 = train_data2016[feature16]\n",
    "y_train16 = train_data2016[label16]\n",
    "\n",
    "# training data and label for model 2017\n",
    "X_train17 = train_data2017[feature17]\n",
    "y_train17 = train_data2017[label17]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression for 2016 train data\n",
      "RidgeCV alpha(lambda):1.00\n",
      "Training MAE: 0.068285\n",
      "Training R^2: 0.002313\n",
      "\n",
      "\n",
      "Ridge Regression for 2017 train data\n",
      "RidgeCV alpha(lambda):1.00\n",
      "Training MAE: 0.070555\n",
      "Training R^2: 0.002564\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "\n",
    "def handle_regrRidge(X_train, y_train):\n",
    "    regrRidge = linear_model.RidgeCV(alphas=(0.1, 1.0, 10.0), normalize=True, cv=10, \n",
    "                                 scoring='neg_mean_absolute_error')\n",
    "    regrRidge.fit(X_train, y_train)\n",
    "    y_pred = regrRidge.predict(X_train)\n",
    "\n",
    "    print(\"RidgeCV alpha(lambda):{:.2f}\".format(regrRidge.alpha_))\n",
    "    print(\"Training MAE: {:.6f}\".format(mean_absolute_error(y_train, y_pred)))\n",
    "    print(\"Training R^2: {:.6f}\".format(r2_score(y_train, y_pred)))\n",
    "    \n",
    "    return regrRidge\n",
    "    \n",
    "\n",
    "print(\"Ridge Regression for 2016 train data\")\n",
    "regrRidge16 = handle_regrRidge(X_train16, y_train16)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Ridge Regression for 2017 train data\")\n",
    "regrRidge17 = handle_regrRidge(X_train17, y_train17)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression for 2016 train data\n",
      "LassoCV alpha(lambda): 0.000002\n",
      "MAE: 0.068257\n",
      "R^2: 0.002827\n",
      "\n",
      "\n",
      "Lasso Regression for 2017 train data\n",
      "LassoCV alpha(lambda): 0.000002\n",
      "MAE: 0.070553\n",
      "R^2: 0.003399\n",
      "\n",
      "\n",
      "[2016] Selected Features[13]:\n",
      "transactiondate\n",
      "calculatedfinishedsquarefeet\n",
      "heatingorsystemtypeid\n",
      "propertylandusetypeid\n",
      "regionidzip\n",
      "yearbuilt\n",
      "landtaxvaluedollarcnt\n",
      "censustractandblock\n",
      "haspoolornot\n",
      "regionidneighborhood\n",
      "unitcnt\n",
      "lotsizesquarefeet\n",
      "finishedfloor1squarefeet\n",
      "\n",
      "\n",
      "[2017] Selected Features[19]:\n",
      "transactiondate\n",
      "bedroomcnt\n",
      "calculatedfinishedsquarefeet\n",
      "fireplacecnt\n",
      "garagetotalsqft\n",
      "latitude\n",
      "longitude\n",
      "propertylandusetypeid\n",
      "rawcensustractandblock\n",
      "regionidcity\n",
      "regionidcounty\n",
      "regionidzip\n",
      "assessmentyear\n",
      "landtaxvaluedollarcnt\n",
      "taxamount\n",
      "haspoolornot\n",
      "unitcnt\n",
      "roomcnt\n",
      "finishedfloor1squarefeet\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LASSO\n",
    "\n",
    "def handle_Lasso(X_train, y_train):\n",
    "    regrLasso = linear_model.LassoCV(eps=0.001, n_alphas=100, normalize=True, cv=10, max_iter=50000)\n",
    "    regrLasso.fit(X_train, y_train)\n",
    "    y_pred = regrLasso.predict(X_train)\n",
    "    \n",
    "    print(\"LassoCV alpha(lambda): {:.6f}\".format(regrLasso.alpha_))\n",
    "    print(\"MAE: {:.6f}\".format(mean_absolute_error(y_train, y_pred)))\n",
    "    print(\"R^2: {:.6f}\".format(r2_score(y_train, y_pred)))\n",
    "    \n",
    "    return regrLasso\n",
    "\n",
    "# return feature given the coef values from model\n",
    "def get_reduced_features(coef, features):\n",
    "    sel_features = []\n",
    "    for i in range(len(coef)):\n",
    "        if coef[i] != 0:\n",
    "            sel_features.append(features[i])\n",
    "    return sel_features\n",
    "\n",
    "print(\"Lasso Regression for 2016 train data\")\n",
    "regrLasso16 = handle_Lasso(X_train16, y_train16)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Lasso Regression for 2017 train data\")\n",
    "regrLasso17 = handle_Lasso(X_train17, y_train17)\n",
    "print(\"\\n\")\n",
    "\n",
    "# selected features from Lasso\n",
    "sel_features16 = get_reduced_features(regrLasso16.coef_, feature)\n",
    "sel_features17 = get_reduced_features(regrLasso17.coef_, feature)\n",
    "\n",
    "print(\"[2016] Selected Features[{}]:\".format(len(sel_features16)))\n",
    "for i in sel_features16:\n",
    "    print(i)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"[2017] Selected Features[{}]:\".format(len(sel_features17)))\n",
    "for i in sel_features17:\n",
    "    print(i)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-14 02:27:47\n",
      "XGBoost Model 2016:\n",
      "alpha (lambda) from CV: 21.5443\n",
      "Train MAE: 0.0678799\n",
      "\n",
      "\n",
      "XGBoost Model 2017:\n",
      "alpha (lambda) from CV: 21.5443\n",
      "Train MAE: 0.0703863\n",
      "\n",
      "\n",
      "2018-07-14 02:48:36\n"
     ]
    }
   ],
   "source": [
    "# XGBoost fit Regression Decision Tree\n",
    "\n",
    "def handle_XGBoost(X_train, y_train):\n",
    "    # alpha values from 0.01 to 1000 up to 10 values log scale\n",
    "    alphalist = np.logspace(-2, 4, 10, endpoint=True)\n",
    "\n",
    "    mse_dict = {}\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    # cross-validate on alpha (regularization strenght) from alphalist\n",
    "    for i in alphalist:\n",
    "        bst = xgb.sklearn.XGBRegressor(reg_alpha=i)\n",
    "        bst.fit(X_train, y_train)\n",
    "        score = cross_val_score(bst, X_train, y_train, cv=kf, scoring='neg_mean_absolute_error').mean()\n",
    "        mse_dict[i] = -score\n",
    "\n",
    "    opt_a = min(mse_dict, key= mse_dict.get)\n",
    "\n",
    "    print(\"alpha (lambda) from CV: {:.6}\".format(opt_a))\n",
    "\n",
    "    # obtain train MAE with CV'ed alpha value\n",
    "    bst = xgb.sklearn.XGBRegressor(reg_alpha=opt_a)\n",
    "    bst.fit(X_train, y_train)\n",
    "    y_pred = bst.predict(X_train)\n",
    "    print(\"Train MAE: {:.6}\".format(mean_absolute_error(y_train, y_pred)))\n",
    "    \n",
    "    return bst\n",
    "\n",
    "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))\n",
    "print(\"XGBoost Model 2016:\")\n",
    "bst16 = handle_XGBoost(X_train16, y_train16)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"XGBoost Model 2017:\")\n",
    "bst17 = handle_XGBoost(X_train17, y_train17)\n",
    "print(\"\\n\")\n",
    "print(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016] num of instances:  2985217\n",
      "[2017] num of instances:  2985217\n"
     ]
    }
   ],
   "source": [
    "# read in test\n",
    "test_data2016 = pd.read_csv(test_datapath_2016, index_col=0)\n",
    "test_data2017 = pd.read_csv(test_datapath_2017, index_col=0)\n",
    "\n",
    "print(\"[2016] num of instances: \", test_data2016.shape[0])\n",
    "print(\"[2017] num of instances: \", test_data2017.shape[0])\n",
    "\n",
    "# save parcelid for merge \n",
    "test_parcelid16 = test_data2016['parcelid']\n",
    "test_parcelid17 = test_data2017['parcelid']\n",
    "\n",
    "# drop parcelid col\n",
    "test_data2016 = test_data2016.drop('parcelid', axis=1)\n",
    "test_data2017 = test_data2017.drop('parcelid', axis=1)\n",
    "\n",
    "# generate transaction date\n",
    "test10_16 = np.repeat(10, test_data2016.shape[0])\n",
    "test11_16 = np.repeat(11, test_data2016.shape[0])\n",
    "test12_16 = np.repeat(12, test_data2016.shape[0])\n",
    "\n",
    "test10_17 = np.repeat(10, test_data2017.shape[0])\n",
    "test11_17 = np.repeat(11, test_data2017.shape[0])\n",
    "test12_17 = np.repeat(12, test_data2017.shape[0])\n",
    "\n",
    "# get new test data with transaction date\n",
    "X_test10_16 = gen_testdata(test_data2016, test10_16)\n",
    "X_test11_16 = gen_testdata(test_data2016, test11_16)\n",
    "X_test12_16 = gen_testdata(test_data2016, test12_16)\n",
    "\n",
    "X_test10_17 = gen_testdata(test_data2017, test10_17)\n",
    "X_test11_17 = gen_testdata(test_data2017, test11_17)\n",
    "X_test12_17 = gen_testdata(test_data2017, test12_17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "\n",
    "y_pred10_16 = bst16.predict(X_test10_16)\n",
    "y_pred11_16 = bst16.predict(X_test11_16)\n",
    "y_pred12_16 = bst16.predict(X_test12_16)\n",
    "\n",
    "y_pred10_17 = bst17.predict(X_test10_17)\n",
    "y_pred11_17 = bst17.predict(X_test11_17)\n",
    "y_pred12_17 = bst17.predict(X_test12_17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Parcelid    201610    201611    201612    201710    201711    201712\n",
      "0         10754147  0.084751  0.084751  0.084751  0.104134  0.104134  0.104134\n",
      "1         10759547  0.030246  0.030246  0.030246  0.096874  0.096874  0.096874\n",
      "2         10843547  0.052090  0.052090  0.052090  0.106128  0.106128  0.106128\n",
      "3         10859147  0.020549  0.020549  0.020549  0.088284  0.088284  0.088284\n",
      "4         10879947  0.001912  0.001912  0.001912  0.009659  0.009659  0.009659\n",
      "5         10898347  0.014306  0.014306  0.014306  0.022779  0.022779  0.022779\n",
      "6         10933547  0.000933  0.000933  0.000933  0.006954  0.006954  0.006954\n",
      "7         10940747  0.017823  0.017823  0.017823  0.028543  0.028543  0.028543\n",
      "8         10954547  0.084149  0.084149  0.084149  0.064016  0.064016  0.064016\n",
      "9         10976347  0.008127  0.008127  0.008127  0.031002  0.031002  0.031002\n",
      "10        11073947  0.008052  0.008052  0.008052  0.019067  0.019067  0.019067\n",
      "11        11114347  0.088350  0.088350  0.088350  0.104530  0.104530  0.104530\n",
      "12        11116947 -0.039896 -0.039896 -0.039896  0.041428  0.041428  0.041428\n",
      "13        11142747  0.088167  0.088167  0.088167  0.145697  0.145697  0.145697\n",
      "14        11193347  0.088586  0.088586  0.088586 -0.015797 -0.015797 -0.015797\n",
      "15        11215747  0.090242  0.090242  0.090242 -0.010933 -0.010933 -0.010933\n",
      "16        11229347  0.090869  0.090869  0.090869  0.139907  0.139907  0.139907\n",
      "17        11287347  0.006244  0.006244  0.006244  0.038223  0.038223  0.038223\n",
      "18        11288547  0.020696  0.020696  0.020696  0.080135  0.080135  0.080135\n",
      "19        11324547  0.029170  0.029170  0.029170  0.032412  0.032412  0.032412\n",
      "20        11391347  0.007765  0.007765  0.007765  0.026743  0.026743  0.026743\n",
      "21        11395747  0.015621  0.015621  0.015621  0.076633  0.076633  0.076633\n",
      "22        11404347  0.004032  0.004032  0.004032  0.010321  0.010321  0.010321\n",
      "23        11405747 -0.000915 -0.000915 -0.000915  0.015540  0.015540  0.015540\n",
      "24        11417147 -0.015730 -0.015730 -0.015730  0.027242  0.027242  0.027242\n",
      "25        11457547  0.087621  0.087621  0.087621  0.039777  0.039777  0.039777\n",
      "26        11488147  0.005561  0.005561  0.005561  0.030456  0.030456  0.030456\n",
      "27        11520747  0.029624  0.029624  0.029624  0.247531  0.247531  0.247531\n",
      "28        11524947 -0.002147 -0.002147 -0.002147  0.002416  0.002416  0.002416\n",
      "29        11544747  0.004247  0.004247  0.004247  0.008391  0.008391  0.008391\n",
      "...            ...       ...       ...       ...       ...       ...       ...\n",
      "2985187  167636430  0.016244  0.016244  0.016244  0.046811  0.046811  0.046811\n",
      "2985188  167690630  0.016244  0.016244  0.016244  0.016346  0.016346  0.016346\n",
      "2985189  167636630  0.016244  0.016244  0.016244  0.045673  0.045673  0.045673\n",
      "2985190   10834030  0.016244  0.016244  0.016244  0.030540  0.030540  0.030540\n",
      "2985191  167637430  0.016244  0.016244  0.016244 -0.002571 -0.002571 -0.002571\n",
      "2985192  167637630  0.016244  0.016244  0.016244 -0.072227 -0.072227 -0.072227\n",
      "2985193  167637230  0.016244  0.016244  0.016244  0.019603  0.019603  0.019603\n",
      "2985194   11645030  0.016244  0.016244  0.016244  0.000553  0.000553  0.000553\n",
      "2985195  167689030  0.016244  0.016244  0.016244  0.018079  0.018079  0.018079\n",
      "2985196  167638630  0.016244  0.016244  0.016244  0.031948  0.031948  0.031948\n",
      "2985197  167638430  0.016244  0.016244  0.016244  0.015795  0.015795  0.015795\n",
      "2985198   14342030  0.016244  0.016244  0.016244  0.125989  0.125989  0.125989\n",
      "2985199  167638230  0.016244  0.016244  0.016244  0.030378  0.030378  0.030378\n",
      "2985200  167637830  0.016244  0.016244  0.016244  0.012347  0.012347  0.012347\n",
      "2985201  167639230  0.016244  0.016244  0.016244  0.029461  0.029461  0.029461\n",
      "2985202   14341030  0.016244  0.016244  0.016244  0.072349  0.072349  0.072349\n",
      "2985203   14341630  0.016244  0.016244  0.016244  0.070152  0.070152  0.070152\n",
      "2985204   14367630  0.016244  0.016244  0.016244  0.043632  0.043632  0.043632\n",
      "2985205  167638830  0.016244  0.016244  0.016244  0.021902  0.021902  0.021902\n",
      "2985206   12572230  0.016244  0.016244  0.016244  0.029625  0.029625  0.029625\n",
      "2985207   14460030  0.016244  0.016244  0.016244  0.030327  0.030327  0.030327\n",
      "2985208   14284830  0.016244  0.016244  0.016244  0.086209  0.086209  0.086209\n",
      "2985209   14285230  0.016244  0.016244  0.016244  0.075412  0.075412  0.075412\n",
      "2985210   14455630  0.016244  0.016244  0.016244  0.121511  0.121511  0.121511\n",
      "2985211   11117630  0.016244  0.016244  0.016244  0.032575  0.032575  0.032575\n",
      "2985212  168176230  0.016244  0.016244  0.016244  0.029504  0.029504  0.029504\n",
      "2985213   14273630  0.016244  0.016244  0.016244  0.028874  0.028874  0.028874\n",
      "2985214  168040630  0.016244  0.016244  0.016244  0.023999  0.023999  0.023999\n",
      "2985215  168040830  0.016244  0.016244  0.016244  0.045127  0.045127  0.045127\n",
      "2985216  168040430  0.016244  0.016244  0.016244  0.023615  0.023615  0.023615\n",
      "\n",
      "[2985217 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "test_dict_16 = {'Parcelid': test_parcelid16, '201610': y_pred10_16, '201611': y_pred11_16, '201612': y_pred12_16}\n",
    "test_dict_17 = {'Parcelid': test_parcelid17, '201710': y_pred10_17, '201711': y_pred11_17, '201712': y_pred12_17}\n",
    "\n",
    "df_test_16 = pd.DataFrame(data=test_dict_16)\n",
    "df_test_17 = pd.DataFrame(data=test_dict_17)\n",
    "\n",
    "df_merged = df_test_16.merge(df_test_17, left_on='Parcelid', right_on='Parcelid', how='outer')\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2985217 7\n"
     ]
    }
   ],
   "source": [
    "# handle submission file\n",
    "submitfile = \"./zillow-data/sample_submission.csv\"\n",
    "\n",
    "submit_df = pd.read_csv(submitfile)\n",
    "print(submit_df.shape[0], submit_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(\"./zillow-data/draft_submission2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
