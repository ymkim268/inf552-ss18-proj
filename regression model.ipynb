{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath_2016 = \"./zillow data/merged_2016 v2.csv\"\n",
    "datapath_2017 = \"./zillow data/merged_2017 v2.csv\"\n",
    "\n",
    "test_datapath_2016 = \"./zillow data/properties_2016 v2.csv\"\n",
    "test_datapath_2017 = \"./zillow data/properties_2017 v2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify 'transactiondate' of df to keep only the month\n",
    "def parse_transactiondate(df):\n",
    "    # modify transactiondate col to keep only the month\n",
    "    new_transactiondate = []\n",
    "    for data in df['transactiondate']:\n",
    "        temp = data.split(\"-\")\n",
    "        new_transactiondate.append(int(temp[1])) # keep only month\n",
    "\n",
    "    new_transactiondate = np.array(new_transactiondate)\n",
    "    new_transactiondate = new_transactiondate.reshape(new_transactiondate.shape[0], 1)\n",
    "\n",
    "    df['transactiondate'] = new_transactiondate\n",
    "\n",
    "# return label index, feature index list\n",
    "# assumes that df label_is_first\n",
    "def split_on_label(df):\n",
    "    return df.columns[0], df.columns[1:]\n",
    "\n",
    "def gen_testdata(df, new_transactiondate):\n",
    "    df_copy = df.copy()\n",
    "    # df_copy['transactiondate'] = new_transactiondate\n",
    "    df_copy.insert(0, 'transactiondate', new_transactiondate)\n",
    "    return df_copy\n",
    "\n",
    "def get_low_var_feature(support_list):\n",
    "    low_var_feature_index = []\n",
    "    support_feature_index = []\n",
    "    for i in range(len(support_list)):\n",
    "        if support_list[i]:\n",
    "            support_feature_index.append(i)\n",
    "        else:\n",
    "            low_var_feature_index.append(i)\n",
    "    return low_var_feature_index, support_feature_index\n",
    "\n",
    "def handle_low_var(sel, train_data, feature_list):\n",
    "    temp_sel = sel.fit(train_data)\n",
    "    low_var_list, support_list = get_low_var_feature(sel.get_support())\n",
    "    exclude_low_var_name = []\n",
    "    for i in low_var_list:\n",
    "        exclude_low_var_name.append(train_data.columns.values[i])\n",
    "\n",
    "    return low_var_list,exclude_low_var_name\n",
    "\n",
    "def removing_missing(X_train, missing_threshold = 0.95):\n",
    "    exclude_missing = []\n",
    "    num_rows = X_train.shape[0]\n",
    "    for col in X_train.columns:\n",
    "        num_missing = X_train[col].isna().sum()\n",
    "        if num_missing == 0:\n",
    "            continue\n",
    "        missing_fraction = num_missing/float(num_rows)\n",
    "        if missing_fraction > missing_threshold:\n",
    "            exclude_missing.append(col)\n",
    "            \n",
    "    return exclude_missing\n",
    "\n",
    "# removing features with unique value\n",
    "def removing_unique(X_train):\n",
    "    exclude_unique = []\n",
    "    for col in X_train.columns:\n",
    "        num_unique = len(X_train[col].unique())\n",
    "        if X_train[col].isna().sum()!=0 and num_unique == 1:\n",
    "            exclude_unique.append(col)\n",
    "            \n",
    "    return exclude_unique\n",
    "\n",
    "def print_list(li,list_name = ''):\n",
    "    print('%s (%d) :' %(list_name,len(li)))\n",
    "    for i in li:\n",
    "        print(i)\n",
    "        \n",
    "def get_train_features(X_train,el1 = [], el2 = [], el3 = [],el4 = []):\n",
    "    train_feature = []\n",
    "    for col in X_train:\n",
    "        if col not in el1 and col not in el2 and col not in el3 and col not in el4:\n",
    "            train_feature.append(col)\n",
    "    return train_feature\n",
    "\n",
    "# geting categorical features\n",
    "def get_cat_feature(X_train, cat_threshold):\n",
    "    cat_feature_inds = []\n",
    "    cat_feature = []\n",
    "    for i,col in enumerate(X_train):\n",
    "        num_uniques = len(X_train[col].unique())\n",
    "        if num_uniques < cat_threshold and not 'sqft' in col and not 'cnt' in col \\\n",
    "        and not 'nbr' in col and not 'number' in col:\n",
    "            cat_feature_inds.append(i)\n",
    "            cat_feature.append(col)\n",
    "    return cat_feature_inds,cat_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016] num of features: 58\n",
      "[2016] num of instances: 90275\n",
      "[2017] num of features: 58\n",
      "[2017] num of instances: 77613\n"
     ]
    }
   ],
   "source": [
    "train_data2016 = pd.read_csv(datapath_2016, index_col=0)\n",
    "train_data2017 = pd.read_csv(datapath_2017, index_col=0)\n",
    "\n",
    "# --- TEMP Fixes for train_data2016 (not well formatted) ---\n",
    "# fix Unamed: 0 at col index 3\n",
    "fix_col = train_data2016.columns.str.contains('unnamed',case = False)\n",
    "train_data2016 = train_data2016.drop(train_data2016.columns[fix_col], axis=1)\n",
    "# --- END ---\n",
    "\n",
    "parcelid16 = train_data2016['parcelid']\n",
    "parcelid17 = train_data2017['parcelid']\n",
    "\n",
    "# drop parcelid (index of properties features)\n",
    "train_data2016 = train_data2016.drop('parcelid', axis=1)\n",
    "train_data2017 = train_data2017.drop('parcelid', axis=1)\n",
    "\n",
    "label16, feature16 = split_on_label(train_data2016)\n",
    "label17, feature17 = split_on_label(train_data2017)\n",
    "\n",
    "print(\"[2016] num of features:\", len(feature16))\n",
    "print(\"[2016] num of instances:\", train_data2016.shape[0])\n",
    "\n",
    "print(\"[2017] num of features:\", len(feature17))\n",
    "print(\"[2017] num of instances:\", train_data2017.shape[0])\n",
    "\n",
    "# modify 'transactiondate' to keep only the month\n",
    "parse_transactiondate(train_data2016)\n",
    "parse_transactiondate(train_data2017)\n",
    "\n",
    "# training data and label for model 2016\n",
    "X_train16 = train_data2016[feature16]\n",
    "y_train16 = train_data2016[label16]\n",
    "\n",
    "# training data and label for model 2017\n",
    "X_train17 = train_data2017[feature17]\n",
    "y_train17 = train_data2017[label17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3411"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del test_data2016,test_data2017\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Freatures with too many missing data\n",
    "exclude_missing16 = removing_missing(X_train16)\n",
    "exclude_missing17 = removing_missing(X_train17)\n",
    "\n",
    "# Removing Features with unique values\n",
    "exclude_unique16 = removing_unique(X_train16)\n",
    "exclude_unique17 = removing_unique(X_train17)\n",
    "\n",
    "# Removing Features with low variance\n",
    "# it should remove features with many missing values that were filled by imputation\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "\n",
    "_, exclude_low_var16 = handle_low_var(sel, X_train16, feature16)\n",
    "_, exclude_low_var17 = handle_low_var(sel, X_train17, feature17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exclude_missing16 (0) :\n",
      "exclude_low_var16 (16) :\n",
      "architecturalstyletypeid\n",
      "buildingclasstypeid\n",
      "decktypeid\n",
      "fireplacecnt\n",
      "hashottuborspa\n",
      "poolcnt\n",
      "pooltypeid10\n",
      "pooltypeid2\n",
      "pooltypeid7\n",
      "storytypeid\n",
      "threequarterbathnbr\n",
      "typeconstructiontypeid\n",
      "numberofstories\n",
      "fireplaceflag\n",
      "assessmentyear\n",
      "taxdelinquencyflag\n",
      "exclude_unique16 (0) :\n",
      "exclude_missing17 (0) :\n",
      "exclude_low_var17 (16) :\n",
      "architecturalstyletypeid\n",
      "buildingclasstypeid\n",
      "decktypeid\n",
      "fireplacecnt\n",
      "hashottuborspa\n",
      "poolcnt\n",
      "pooltypeid10\n",
      "pooltypeid2\n",
      "pooltypeid7\n",
      "storytypeid\n",
      "threequarterbathnbr\n",
      "typeconstructiontypeid\n",
      "numberofstories\n",
      "fireplaceflag\n",
      "assessmentyear\n",
      "taxdelinquencyflag\n",
      "exclude_unique17 (0) :\n"
     ]
    }
   ],
   "source": [
    "print_list(exclude_missing16,'exclude_missing16')\n",
    "print_list(exclude_low_var16,'exclude_low_var16')\n",
    "print_list(exclude_unique16,'exclude_unique16')\n",
    "print_list(exclude_missing17,'exclude_missing17')\n",
    "print_list(exclude_low_var17,'exclude_low_var17')\n",
    "print_list(exclude_unique17,'exclude_unique17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2016] num of features: 42\n",
      "train_feature16 (42) :\n",
      "transactiondate\n",
      "airconditioningtypeid\n",
      "basementsqft\n",
      "bathroomcnt\n",
      "bedroomcnt\n",
      "buildingqualitytypeid\n",
      "calculatedbathnbr\n",
      "finishedfloor1squarefeet\n",
      "calculatedfinishedsquarefeet\n",
      "finishedsquarefeet12\n",
      "finishedsquarefeet13\n",
      "finishedsquarefeet15\n",
      "finishedsquarefeet50\n",
      "finishedsquarefeet6\n",
      "fips\n",
      "fullbathcnt\n",
      "garagecarcnt\n",
      "garagetotalsqft\n",
      "heatingorsystemtypeid\n",
      "latitude\n",
      "longitude\n",
      "lotsizesquarefeet\n",
      "poolsizesum\n",
      "propertycountylandusecode\n",
      "propertylandusetypeid\n",
      "propertyzoningdesc\n",
      "rawcensustractandblock\n",
      "regionidcity\n",
      "regionidcounty\n",
      "regionidneighborhood\n",
      "regionidzip\n",
      "roomcnt\n",
      "unitcnt\n",
      "yardbuildingsqft17\n",
      "yardbuildingsqft26\n",
      "yearbuilt\n",
      "structuretaxvaluedollarcnt\n",
      "taxvaluedollarcnt\n",
      "landtaxvaluedollarcnt\n",
      "taxamount\n",
      "taxdelinquencyyear\n",
      "censustractandblock\n"
     ]
    }
   ],
   "source": [
    "train_feature16 = get_train_features(X_train16, el1 = exclude_missing16, \n",
    "                                                el2 = exclude_low_var16,\n",
    "                                                el3 = exclude_unique16)\n",
    "\n",
    "new_X_train16 = X_train16[train_feature16]\n",
    "\n",
    "print(\"\\n[2016] num of features:\", new_X_train16.shape[1])\n",
    "print_list(train_feature16,\"train_feature16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2017] num of features: 42\n",
      "train_feature17 (42) :\n",
      "transactiondate\n",
      "airconditioningtypeid\n",
      "basementsqft\n",
      "bathroomcnt\n",
      "bedroomcnt\n",
      "buildingqualitytypeid\n",
      "calculatedbathnbr\n",
      "finishedfloor1squarefeet\n",
      "calculatedfinishedsquarefeet\n",
      "finishedsquarefeet12\n",
      "finishedsquarefeet13\n",
      "finishedsquarefeet15\n",
      "finishedsquarefeet50\n",
      "finishedsquarefeet6\n",
      "fips\n",
      "fullbathcnt\n",
      "garagecarcnt\n",
      "garagetotalsqft\n",
      "heatingorsystemtypeid\n",
      "latitude\n",
      "longitude\n",
      "lotsizesquarefeet\n",
      "poolsizesum\n",
      "propertycountylandusecode\n",
      "propertylandusetypeid\n",
      "propertyzoningdesc\n",
      "rawcensustractandblock\n",
      "regionidcity\n",
      "regionidcounty\n",
      "regionidneighborhood\n",
      "regionidzip\n",
      "roomcnt\n",
      "unitcnt\n",
      "yardbuildingsqft17\n",
      "yardbuildingsqft26\n",
      "yearbuilt\n",
      "structuretaxvaluedollarcnt\n",
      "taxvaluedollarcnt\n",
      "landtaxvaluedollarcnt\n",
      "taxamount\n",
      "taxdelinquencyyear\n",
      "censustractandblock\n"
     ]
    }
   ],
   "source": [
    "train_feature17 = get_train_features(X_train16, el1 = exclude_missing17, \n",
    "                                                el2 = exclude_low_var17,\n",
    "                                                el3 = exclude_unique17)\n",
    "\n",
    "new_X_train17 = X_train17[train_feature17]\n",
    "\n",
    "print(\"\\n[2017] num of features:\", new_X_train17.shape[1])\n",
    "print_list(train_feature16,\"train_feature17\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression for 2016 train data\n",
      "CV score:0.068565\n",
      "Training MAE: 0.068438\n",
      "Training R^2: 0.005605\n",
      "\n",
      "\n",
      "Linear Regression for 2017 train data\n",
      "CV score:0.071193\n",
      "Training MAE: 0.070902\n",
      "Training R^2: 0.006266\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "\n",
    "def handle_linearRidge(X_train, y_train):\n",
    "    lr = linear_model.LinearRegression()\n",
    "    score = -1*model_selection.cross_val_score(lr, X_train, y_train, cv=10, scoring='neg_mean_absolute_error').mean()\n",
    "    lr.fit(X_train,y_train)\n",
    "    y_pred = lr.predict(X_train)\n",
    "    \n",
    "    print(\"CV score:{:.6f}\".format(score))\n",
    "    print(\"Training MAE: {:.6f}\".format(mean_absolute_error(y_train, y_pred)))\n",
    "    print(\"Training R^2: {:.6f}\".format(r2_score(y_train, y_pred)))\n",
    "    \n",
    "    return lr\n",
    "    \n",
    "\n",
    "print(\"Linear Regression for 2016 train data\")\n",
    "lr16 = handle_linearRidge(X_train16, y_train16)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Linear Regression for 2017 train data\")\n",
    "lr17 = handle_linearRidge(X_train17, y_train17)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression for 2016 train data\n",
      "RidgeCV alpha(lambda):1.00\n",
      "Training MAE: 0.068308\n",
      "Training R^2: 0.002671\n",
      "\n",
      "\n",
      "Ridge Regression for 2017 train data\n",
      "RidgeCV alpha(lambda):1.00\n",
      "Training MAE: 0.070545\n",
      "Training R^2: 0.004104\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "\n",
    "def handle_regrRidge(X_train, y_train):\n",
    "    regrRidge = linear_model.RidgeCV( normalize=True, gcv_mode = 'auto', \n",
    "                                 scoring='neg_mean_absolute_error',store_cv_values = True)\n",
    "    regrRidge.fit(X_train, y_train)\n",
    "    y_pred = regrRidge.predict(X_train)\n",
    "    \n",
    "    #best_score = np.min(regrRidge.cv_values_)\n",
    "\n",
    "    print(\"RidgeCV alpha(lambda):{:.2f}\".format(regrRidge.alpha_))\n",
    "    #print(\"best CV score:%f\"%best_score)\n",
    "    print(\"Training MAE: {:.6f}\".format(mean_absolute_error(y_train, y_pred)))\n",
    "    print(\"Training R^2: {:.6f}\".format(r2_score(y_train, y_pred)))\n",
    "    \n",
    "    return regrRidge\n",
    "    \n",
    "\n",
    "print(\"Ridge Regression for 2016 train data\")\n",
    "regrRidge16 = handle_regrRidge(X_train16, y_train16)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Ridge Regression for 2017 train data\")\n",
    "regrRidge17 = handle_regrRidge(X_train17, y_train17)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression for 2016 train data\n",
      "LassoCV alpha(lambda): 0.000001\n",
      "MAE: 0.068305\n",
      "R^2: 0.004544\n",
      "\n",
      "\n",
      "Lasso Regression for 2017 train data\n",
      "LassoCV alpha(lambda): 0.000002\n",
      "MAE: 0.070681\n",
      "R^2: 0.005414\n",
      "\n",
      "\n",
      "[2016] Selected Features[23]:\n",
      "transactiondate\n",
      "architecturalstyletypeid\n",
      "calculatedbathnbr\n",
      "decktypeid\n",
      "finishedfloor1squarefeet\n",
      "calculatedfinishedsquarefeet\n",
      "finishedsquarefeet13\n",
      "fips\n",
      "fireplacecnt\n",
      "fullbathcnt\n",
      "garagetotalsqft\n",
      "heatingorsystemtypeid\n",
      "latitude\n",
      "longitude\n",
      "pooltypeid2\n",
      "propertycountylandusecode\n",
      "propertylandusetypeid\n",
      "rawcensustractandblock\n",
      "regionidcity\n",
      "regionidcounty\n",
      "regionidzip\n",
      "roomcnt\n",
      "storytypeid\n",
      "\n",
      "\n",
      "[2017] Selected Features[24]:\n",
      "transactiondate\n",
      "airconditioningtypeid\n",
      "architecturalstyletypeid\n",
      "bathroomcnt\n",
      "bedroomcnt\n",
      "decktypeid\n",
      "calculatedfinishedsquarefeet\n",
      "finishedsquarefeet12\n",
      "finishedsquarefeet13\n",
      "fips\n",
      "fireplacecnt\n",
      "fullbathcnt\n",
      "garagecarcnt\n",
      "garagetotalsqft\n",
      "latitude\n",
      "longitude\n",
      "pooltypeid10\n",
      "pooltypeid2\n",
      "pooltypeid7\n",
      "propertylandusetypeid\n",
      "regionidcity\n",
      "regionidzip\n",
      "roomcnt\n",
      "storytypeid\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LASSO\n",
    "\n",
    "def handle_Lasso(X_train, y_train):\n",
    "    regrLasso = linear_model.LassoCV(eps=0.001, n_alphas=100, normalize=True, cv=10, max_iter=50000)\n",
    "    regrLasso.fit(X_train, y_train)\n",
    "    y_pred = regrLasso.predict(X_train)\n",
    "    \n",
    "    print(\"LassoCV alpha(lambda): {:.6f}\".format(regrLasso.alpha_))\n",
    "    print(\"MAE: {:.6f}\".format(mean_absolute_error(y_train, y_pred)))\n",
    "    print(\"R^2: {:.6f}\".format(r2_score(y_train, y_pred)))\n",
    "    \n",
    "    return regrLasso\n",
    "\n",
    "# return feature given the coef values from model\n",
    "def get_reduced_features(coef,features):\n",
    "    sel_features = []\n",
    "    for i in range(len(coef)):\n",
    "        if coef[i] != 0:\n",
    "            sel_features.append(features[i])\n",
    "    return sel_features\n",
    "\n",
    "print(\"Lasso Regression for 2016 train data\")\n",
    "regrLasso16 = handle_Lasso(new_X_train16, y_train16)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Lasso Regression for 2017 train data\")\n",
    "regrLasso17 = handle_Lasso(new_X_train17, y_train17)\n",
    "print(\"\\n\")\n",
    "\n",
    "# selected features from Lasso\n",
    "sel_features16 = get_reduced_features(regrLasso16.coef_,X_train16.columns)\n",
    "sel_features17 = get_reduced_features(regrLasso17.coef_,X_train17.columns)\n",
    "\n",
    "print(\"[2016] Selected Features[{}]:\".format(len(sel_features16)))\n",
    "for i in sel_features16:\n",
    "    print(i)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"[2017] Selected Features[{}]:\".format(len(sel_features17)))\n",
    "for i in sel_features17:\n",
    "    print(i)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Regression for 2016 train data\n",
      "ElasticCV alpha(lambda): 0.000001\n",
      "ElasticCV l1_ratio: 0.900000\n",
      "MAE: 0.068322\n",
      "R^2: 0.004813\n",
      "\n",
      "\n",
      "Elastic Regression for 2017 train data\n",
      "ElasticCV alpha(lambda): 0.000002\n",
      "ElasticCV l1_ratio: 0.900000\n",
      "MAE: 0.070675\n",
      "R^2: 0.005404\n",
      "\n",
      "\n",
      "[2016] Selected Features[32]:\n",
      "transactiondate\n",
      "airconditioningtypeid\n",
      "architecturalstyletypeid\n",
      "basementsqft\n",
      "bathroomcnt\n",
      "bedroomcnt\n",
      "calculatedbathnbr\n",
      "decktypeid\n",
      "finishedfloor1squarefeet\n",
      "calculatedfinishedsquarefeet\n",
      "finishedsquarefeet13\n",
      "finishedsquarefeet6\n",
      "fips\n",
      "fireplacecnt\n",
      "fullbathcnt\n",
      "garagecarcnt\n",
      "garagetotalsqft\n",
      "heatingorsystemtypeid\n",
      "latitude\n",
      "longitude\n",
      "poolcnt\n",
      "pooltypeid10\n",
      "pooltypeid2\n",
      "propertycountylandusecode\n",
      "propertylandusetypeid\n",
      "propertyzoningdesc\n",
      "rawcensustractandblock\n",
      "regionidcity\n",
      "regionidcounty\n",
      "regionidzip\n",
      "roomcnt\n",
      "storytypeid\n",
      "\n",
      "\n",
      "[2017] Selected Features[24]:\n",
      "transactiondate\n",
      "airconditioningtypeid\n",
      "architecturalstyletypeid\n",
      "bathroomcnt\n",
      "bedroomcnt\n",
      "decktypeid\n",
      "calculatedfinishedsquarefeet\n",
      "finishedsquarefeet12\n",
      "finishedsquarefeet13\n",
      "fips\n",
      "fireplacecnt\n",
      "fullbathcnt\n",
      "garagecarcnt\n",
      "garagetotalsqft\n",
      "latitude\n",
      "longitude\n",
      "pooltypeid10\n",
      "pooltypeid2\n",
      "pooltypeid7\n",
      "propertylandusetypeid\n",
      "regionidcity\n",
      "regionidzip\n",
      "roomcnt\n",
      "storytypeid\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def handle_Elastic(X_train, y_train):\n",
    "    regrElastic = linear_model.ElasticNetCV(l1_ratio = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],cv=10, random_state=0,\n",
    "                                            max_iter = 50000,normalize = True)\n",
    "    regrElastic.fit(X_train, y_train)\n",
    "    y_pred = regrElastic.predict(X_train)\n",
    "    \n",
    "    print(\"ElasticCV alpha(lambda): {:.6f}\".format(regrElastic.alpha_))\n",
    "    print(\"ElasticCV l1_ratio: {:.6f}\".format(regrElastic.l1_ratio_))\n",
    "    print(\"MAE: {:.6f}\".format(mean_absolute_error(y_train, y_pred)))\n",
    "    print(\"R^2: {:.6f}\".format(r2_score(y_train, y_pred)))\n",
    "    \n",
    "    return regrElastic\n",
    "\n",
    "print(\"Elastic Regression for 2016 train data\")\n",
    "regrElastic16 = handle_Elastic(new_X_train16, y_train16)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Elastic Regression for 2017 train data\")\n",
    "regrElastic17 = handle_Elastic(new_X_train17, y_train17)\n",
    "print(\"\\n\")\n",
    "\n",
    "# return feature given the coef values from model\n",
    "def get_reduced_features(coef, features):\n",
    "    sel_features = []\n",
    "    for i in range(len(coef)):\n",
    "        if coef[i] != 0:\n",
    "            sel_features.append(features[i])\n",
    "    return sel_features\n",
    "\n",
    "# selected features from Lasso\n",
    "sel_features16 = get_reduced_features(regrElastic16.coef_, X_train16.columns)\n",
    "sel_features17 = get_reduced_features(regrElastic17.coef_, X_train17.columns)\n",
    "\n",
    "print(\"[2016] Selected Features[{}]:\".format(len(sel_features16)))\n",
    "for i in sel_features16:\n",
    "    print(i)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"[2017] Selected Features[{}]:\".format(len(sel_features17)))\n",
    "for i in sel_features17:\n",
    "    print(i)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate Outlier Using RANSAC Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 698.33 seconds parameter settings.\n",
      "[mean: -0.06818, std: 0.00322, params: {'min_samples': 0.2, 'random_state': 42}, mean: -0.06814, std: 0.00309, params: {'min_samples': 0.5, 'random_state': 42}, mean: -0.06814, std: 0.00306, params: {'min_samples': 0.8, 'random_state': 42}]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "def handle_ransac_GridCV(X, y, param_dict,estimator):\n",
    "    \n",
    "    # cross-validate on alpha (regularization strenght) from alphalist\n",
    "    \n",
    "    ransac = linear_model.RANSACRegressor(estimator, random_state= 21)\n",
    "       \n",
    "    # cross-validate on random search CV\n",
    "    grid_search = GridSearchCV(ransac,param_grid=param_dict,\n",
    "                               cv=5, scoring='neg_mean_absolute_error')\n",
    "    \n",
    "    start = time.time()\n",
    "    grid_search.fit(X, y)\n",
    "    print(\"GridSearchCV took %.2f seconds\"\n",
    "          \" parameter settings.\" % (time.time() - start))\n",
    "\n",
    "    return grid_search\n",
    "\n",
    "param_dict = {\n",
    "    'min_samples':[0.2,0.5,0.8],\n",
    "    'random_state':[42]\n",
    "}\n",
    "grid_result = handle_ransac_GridCV(X_train16, y_train16, param_dict,regrRidge16)\n",
    "print(grid_result.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ransac Regression based on Lasso for 2016 train data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-5d4a046f9531>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ransac Regression based on Lasso for 2016 train data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mransac16\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_Ransac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregrLasso16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-148-5d4a046f9531>\u001b[0m in \u001b[0;36mhandle_Ransac\u001b[0;34m(X_train, y_train, estimator)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhandle_Ransac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mransac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRANSACRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_trials\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mransac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mransac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/sklearn/linear_model/ransac.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;31m# fit model for current random sample set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m                 \u001b[0mbase_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m                 base_estimator.fit(X_subset, y_subset,\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy_X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecompute\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'l1_ratio'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_ratio_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, check_input)\u001b[0m\n\u001b[1;32m    750\u001b[0m                           \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m                           \u001b[0mselection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m                           check_input=False)\n\u001b[0m\u001b[1;32m    753\u001b[0m             \u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis_coef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m             \u001b[0mdual_gaps_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis_dual_gap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    475\u001b[0m             model = cd_fast.enet_coordinate_descent(\n\u001b[1;32m    476\u001b[0m                 \u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m                 positive)\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             raise ValueError(\"Precompute should be one of True, False, \"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "def handle_Ransac(X_train, y_train,estimator):\n",
    "    ransac = linear_model.RANSACRegressor(estimator, max_trials= 2,min_samples = 0.8, random_state= 21)\n",
    "    ransac.fit(X_train, y_train)\n",
    "    y_pred = ransac.predict(X_train)\n",
    "    \n",
    "    print(\"MAE: {:.6f}\".format(mean_absolute_error(y_train, y_pred)))\n",
    "    print(\"R^2: {:.6f}\".format(r2_score(y_train, y_pred)))\n",
    "    \n",
    "    return ransac\n",
    "\n",
    "\n",
    "print(\"ransac Regression based on Lasso for 2016 train data\")\n",
    "ransac16 = handle_Ransac(new_X_train16, y_train16, regrLasso16)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"ransac Regression based on Lasso for 2017 train data\")\n",
    "ransac17 = handle_Ransac(new_X_train17, y_train17,regrLasso17)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37038, 58)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inlier = ransac17.inlier_mask_\n",
    "X_train17[inlier].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2016] num of instances:  2985217\n",
      "[2017] num of instances:  2985217\n"
     ]
    }
   ],
   "source": [
    "# read in test\n",
    "test_data2016 = pd.read_csv(test_datapath_2016, index_col=0)\n",
    "test_data2017 = pd.read_csv(test_datapath_2017, index_col=0)\n",
    "\n",
    "print(\"[2016] num of instances: \", test_data2016.shape[0])\n",
    "print(\"[2017] num of instances: \", test_data2017.shape[0])\n",
    "\n",
    "# save parcelid for merge \n",
    "test_parcelid16 = test_data2016['parcelid']\n",
    "test_parcelid17 = test_data2017['parcelid']\n",
    "\n",
    "# drop parcelid col\n",
    "test_data2016 = test_data2016.drop('parcelid', axis=1)\n",
    "test_data2017 = test_data2017.drop('parcelid', axis=1)\n",
    "\n",
    "# generate transaction date\n",
    "test10_16 = np.repeat(10, test_data2016.shape[0])\n",
    "test11_16 = np.repeat(11, test_data2016.shape[0])\n",
    "test12_16 = np.repeat(12, test_data2016.shape[0])\n",
    "\n",
    "test10_17 = np.repeat(10, test_data2017.shape[0])\n",
    "test11_17 = np.repeat(11, test_data2017.shape[0])\n",
    "test12_17 = np.repeat(12, test_data2017.shape[0])\n",
    "\n",
    "# get new test data with transaction date\n",
    "X_test10_16 = gen_testdata(test_data2016, test10_16)\n",
    "X_test11_16 = gen_testdata(test_data2016, test11_16)\n",
    "X_test12_16 = gen_testdata(test_data2016, test12_16)\n",
    "\n",
    "X_test10_17 = gen_testdata(test_data2017, test10_17)\n",
    "X_test11_17 = gen_testdata(test_data2017, test11_17)\n",
    "X_test12_17 = gen_testdata(test_data2017, test12_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_test10_16 = X_test10_16[train_feature16]\n",
    "new_X_test11_16 = X_test11_16[train_feature16]\n",
    "new_X_test12_16 = X_test12_16[train_feature16]\n",
    "new_X_test10_17 = X_test10_17[train_feature17]\n",
    "new_X_test11_17 = X_test11_17[train_feature17]\n",
    "new_X_test12_17 = X_test12_17[train_feature17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "estimator16 = ransac16\n",
    "estimator17 = ransac17\n",
    "\n",
    "\n",
    "y_pred10_16 = estimator16.predict(X_test10_16)\n",
    "y_pred11_16 = estimator16.predict(X_test11_16)\n",
    "y_pred12_16 = estimator16.predict(X_test12_16)\n",
    "\n",
    "y_pred10_17 = estimator17.predict(X_test10_17)\n",
    "y_pred11_17 = estimator17.predict(X_test11_17)\n",
    "y_pred12_17 = estimator17.predict(X_test12_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Parcelid    201610    201611    201612    201710    201711    201712\n",
      "0         10754147  0.009440  0.009755  0.010070  0.018298  0.018513  0.018729\n",
      "1         10759547  0.006874  0.007189  0.007504 -0.055544 -0.055329 -0.055113\n",
      "2         10843547  0.371188  0.371503  0.371817 -0.030462 -0.030246 -0.030031\n",
      "3         10859147 -0.043541 -0.043226 -0.042911 -0.077121 -0.076906 -0.076691\n",
      "4         10879947 -0.064411 -0.064096 -0.063781 -0.079790 -0.079575 -0.079359\n",
      "5         10898347 -0.058624 -0.058310 -0.057995 -0.073544 -0.073329 -0.073114\n",
      "6         10933547  0.012210  0.012525  0.012840  0.011037  0.011252  0.011468\n",
      "7         10940747 -0.052904 -0.052589 -0.052274 -0.076614 -0.076399 -0.076183\n",
      "8         10954547  0.009852  0.010167  0.010482  0.021300  0.021516  0.021731\n",
      "9         10976347 -0.054011 -0.053696 -0.053381 -0.075587 -0.075372 -0.075157\n",
      "10        11073947 -0.055288 -0.054974 -0.054659 -0.074072 -0.073856 -0.073641\n",
      "11        11114347  0.006660  0.006975  0.007290  0.016874  0.017090  0.017305\n",
      "12        11116947  0.011738  0.012053  0.012368  0.016355  0.016570  0.016786\n",
      "13        11142747 -0.000023  0.000292  0.000607 -0.053833 -0.053617 -0.053402\n",
      "14        11193347  0.003574  0.003889  0.004204  0.012959  0.013175  0.013390\n",
      "15        11215747  0.003505  0.003820  0.004135  0.013361  0.013576  0.013792\n",
      "16        11229347  0.014884  0.015199  0.015514  0.015618  0.015833  0.016049\n",
      "17        11287347 -0.060569 -0.060254 -0.059939 -0.070506 -0.070291 -0.070076\n",
      "18        11288547  0.023240  0.023555  0.023870  0.047156  0.047371  0.047587\n",
      "19        11324547  0.022786  0.023101  0.023416  0.030466  0.030681  0.030896\n",
      "20        11391347 -0.050873 -0.050558 -0.050243 -0.074963 -0.074748 -0.074533\n",
      "21        11395747 -0.063995 -0.063680 -0.063366 -0.077071 -0.076856 -0.076640\n",
      "22        11404347 -0.057676 -0.057361 -0.057046 -0.059713 -0.059498 -0.059282\n",
      "23        11405747 -0.064723 -0.064408 -0.064093 -0.071985 -0.071770 -0.071554\n",
      "24        11417147 -0.055751 -0.055436 -0.055121 -0.070177 -0.069961 -0.069746\n",
      "25        11457547  0.007252  0.007567  0.007882  0.014669  0.014884  0.015100\n",
      "26        11488147  0.010641  0.010956  0.011271  0.007907  0.008122  0.008338\n",
      "27        11520747 -0.031937 -0.031622 -0.031307 -0.067402 -0.067187 -0.066971\n",
      "28        11524947  0.005908  0.006223  0.006538  0.004415  0.004630  0.004846\n",
      "29        11544747  0.008961  0.009276  0.009591 -0.003422 -0.003207 -0.002992\n",
      "...            ...       ...       ...       ...       ...       ...       ...\n",
      "2985187  167636430  0.013580  0.013895  0.014210  0.017142  0.017357  0.017572\n",
      "2985188  167690630  0.013580  0.013895  0.014210  0.006658  0.006873  0.007088\n",
      "2985189  167636630  0.013580  0.013895  0.014210  0.015658  0.015873  0.016088\n",
      "2985190   10834030  0.013580  0.013895  0.014210  0.029877  0.030092  0.030308\n",
      "2985191  167637430  0.013580  0.013895  0.014210  0.011892  0.012107  0.012322\n",
      "2985192  167637630  0.013580  0.013895  0.014210 -0.129578 -0.129363 -0.129148\n",
      "2985193  167637230  0.013580  0.013895  0.014210 -0.003026 -0.002810 -0.002595\n",
      "2985194   11645030  0.013580  0.013895  0.014210  0.015603  0.015818  0.016034\n",
      "2985195  167689030  0.013580  0.013895  0.014210  0.017102  0.017317  0.017532\n",
      "2985196  167638630  0.013580  0.013895  0.014210  0.018681  0.018896  0.019111\n",
      "2985197  167638430  0.013580  0.013895  0.014210  0.019302  0.019517  0.019732\n",
      "2985198   14342030  0.013580  0.013895  0.014210  0.041338  0.041553  0.041769\n",
      "2985199  167638230  0.013580  0.013895  0.014210  0.011578  0.011793  0.012008\n",
      "2985200  167637830  0.013580  0.013895  0.014210  0.010541  0.010756  0.010972\n",
      "2985201  167639230  0.013580  0.013895  0.014210  0.019253  0.019468  0.019683\n",
      "2985202   14341030  0.013580  0.013895  0.014210  0.026294  0.026509  0.026724\n",
      "2985203   14341630  0.013580  0.013895  0.014210  0.022240  0.022455  0.022671\n",
      "2985204   14367630  0.013580  0.013895  0.014210  0.019127  0.019342  0.019558\n",
      "2985205  167638830  0.013580  0.013895  0.014210  0.002608  0.002823  0.003039\n",
      "2985206   12572230  0.013580  0.013895  0.014210  0.019617  0.019833  0.020048\n",
      "2985207   14460030  0.013580  0.013895  0.014210  0.012630  0.012845  0.013060\n",
      "2985208   14284830  0.013580  0.013895  0.014210  0.019328  0.019543  0.019759\n",
      "2985209   14285230  0.013580  0.013895  0.014210  0.034491  0.034706  0.034921\n",
      "2985210   14455630  0.013580  0.013895  0.014210  0.040565  0.040780  0.040996\n",
      "2985211   11117630  0.013580  0.013895  0.014210  0.029203  0.029418  0.029634\n",
      "2985212  168176230  0.013580  0.013895  0.014210  0.017345  0.017561  0.017776\n",
      "2985213   14273630  0.013580  0.013895  0.014210  0.015625  0.015841  0.016056\n",
      "2985214  168040630  0.013580  0.013895  0.014210  0.010486  0.010701  0.010916\n",
      "2985215  168040830  0.013580  0.013895  0.014210  0.020709  0.020924  0.021139\n",
      "2985216  168040430  0.013580  0.013895  0.014210  0.012502  0.012717  0.012933\n",
      "\n",
      "[2985217 rows x 7 columns]\n",
      "2985217 7\n"
     ]
    }
   ],
   "source": [
    "test_dict_16 = {'Parcelid': test_parcelid16, '201610': y_pred10_16, '201611': y_pred11_16, '201612': y_pred12_16}\n",
    "test_dict_17 = {'Parcelid': test_parcelid17, '201710': y_pred10_17, '201711': y_pred11_17, '201712': y_pred12_17}\n",
    "\n",
    "df_test_16 = pd.DataFrame(data=test_dict_16)\n",
    "df_test_17 = pd.DataFrame(data=test_dict_17)\n",
    "\n",
    "df_merged = df_test_16.merge(df_test_17, left_on='Parcelid', right_on='Parcelid', how='outer')\n",
    "print(df_merged)\n",
    "\n",
    "# handle submission file\n",
    "submitfile = \"./zillow data/sample_submission.csv\"\n",
    "\n",
    "submit_df = pd.read_csv(submitfile)\n",
    "print(submit_df.shape[0], submit_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(\"./zillow data/reg_submission4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/Lasso17 42.m']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(ransac16, \"./model/ransac16 58.m\")\n",
    "joblib.dump(ransac17, \"./model/ransac17 58.m\")\n",
    "joblib.dump(lr16, \"./model/lr16 58.m\")\n",
    "joblib.dump(lr17, \"./model/lr17 58.m\")\n",
    "joblib.dump(regrLasso16, \"./model/Lasso16 42.m\")\n",
    "joblib.dump(regrLasso17, \"./model/Lasso17 42.m\")\n",
    "joblib.dump(regrRidge16, \"./model/Ridge16 42.m\")\n",
    "joblib.dump(regrRidge17, \"./model/Ridge17 42.m\")\n",
    "joblib.dump(regrElastic16, \"./model/Lasso16 42.m\")\n",
    "joblib.dump(regrElastic17, \"./model/Lasso17 42.m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
